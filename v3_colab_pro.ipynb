{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UrbanSound8K Classification — Colab Pro\n",
        "\n",
        "**Hardware options (Runtime → Change runtime type):**\n",
        "- `T4 GPU` — Free / Pro: baseline option, ~16 GB VRAM\n",
        "- `A100 GPU` — Pro+: fastest, use if available\n",
        "- `V100 GPU` — Pro: good middle ground\n",
        "- `TPU v2-8` — Experimental only; PyTorch on TPU requires extra setup, **use GPU instead**\n",
        "\n",
        "**Recommended for this project: T4 or A100 GPU**\n",
        "\n",
        "This notebook persists all checkpoints to Google Drive.\n",
        "Run it across multiple sessions — completed folds are skipped automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Cell 1: Check hardware ──────────────────────────────────────\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_mem  = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f'GPU: {gpu_name}')\n",
        "    print(f'VRAM: {gpu_mem:.1f} GB')\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    print('No GPU! Go to Runtime → Change runtime type → GPU')\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "print(f'Device: {DEVICE}')\n",
        "print(f'PyTorch: {torch.__version__}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Cell 2: Mount Drive & set paths ────────────────────────────\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# !! EDIT THESE to match your Drive structure\n",
        "DRIVE_ROOT       = '/content/drive/MyDrive/ECE176_project'\n",
        "DATASET_ROOT     = os.path.join(DRIVE_ROOT, 'UrbanSound8K')\n",
        "CHECKPOINT_DIR   = os.path.join(DRIVE_ROOT, 'checkpoints')\n",
        "RESULTS_DIR      = os.path.join(DRIVE_ROOT, 'results')\n",
        "CACHE_DIR        = os.path.join(DRIVE_ROOT, 'cache')\n",
        "\n",
        "for d in [CHECKPOINT_DIR, RESULTS_DIR, CACHE_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "print('Drive mounted.')\n",
        "print(f'Dataset: {DATASET_ROOT}')\n",
        "print(f'Dataset exists: {os.path.exists(DATASET_ROOT)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Cell 3: Download dataset via Kaggle (first time only) ───────\n",
        "# Skip if UrbanSound8K folder already exists in Drive\n",
        "import os\n",
        "\n",
        "if os.path.exists(os.path.join(DATASET_ROOT, 'metadata', 'UrbanSound8K.csv')):\n",
        "    print('Dataset already present. Skipping download.')\n",
        "else:\n",
        "    print('Dataset not found. Downloading from Kaggle...')\n",
        "    # Upload your kaggle.json first via Files panel on the left\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "    !cp /content/kaggle.json /root/.kaggle/\n",
        "    !chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "    !pip install -q kaggle\n",
        "    !kaggle datasets download -d chrisfilo/urbansound8k -p /content/\n",
        "    !unzip -q /content/urbansound8k.zip -d /content/UrbanSound8K_tmp\n",
        "\n",
        "    import shutil\n",
        "    shutil.move('/content/UrbanSound8K_tmp', DATASET_ROOT)\n",
        "    print('Download complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Cell 4: Install dependencies ────────────────────────────────\n",
        "!pip install -q librosa scikit-learn tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Cell 5: Core utilities (inline — no local files needed) ─────\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import json\n",
        "\n",
        "# ── Constants ──\n",
        "CLASSES = ['air_conditioner','car_horn','children_playing','dog_bark',\n",
        "           'drilling','engine_idling','gun_shot','jackhammer','siren','street_music']\n",
        "SAMPLE_RATE = 22050\n",
        "CLIP_DURATION = 4.0\n",
        "N_MFCC = 40\n",
        "N_MELS = 128\n",
        "HOP_LENGTH = 512\n",
        "N_FFT = 2048\n",
        "MEL_LENGTH = 128\n",
        "\n",
        "# ── Audio loading ──\n",
        "def load_audio(path, sr=SAMPLE_RATE, duration=CLIP_DURATION):\n",
        "    try:\n",
        "        y, _ = librosa.load(path, sr=sr, duration=duration, mono=True)\n",
        "    except:\n",
        "        return np.zeros(int(sr * duration), dtype=np.float32)\n",
        "    target_len = int(sr * duration)\n",
        "    if len(y) < target_len:\n",
        "        y = np.pad(y, (0, target_len - len(y)))\n",
        "    return y[:target_len].astype(np.float32)\n",
        "\n",
        "# ── Feature extraction ──\n",
        "def extract_mfcc(y, sr=SAMPLE_RATE):\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
        "    return np.concatenate([mfcc.mean(axis=1), mfcc.std(axis=1)])\n",
        "\n",
        "def extract_mel(y, sr=SAMPLE_RATE, fixed_length=MEL_LENGTH):\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS,\n",
        "                                          n_fft=N_FFT, hop_length=HOP_LENGTH, fmax=8000)\n",
        "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
        "    if log_mel.shape[1] < fixed_length:\n",
        "        log_mel = np.pad(log_mel, ((0,0),(0, fixed_length - log_mel.shape[1])),\n",
        "                         constant_values=log_mel.min())\n",
        "    else:\n",
        "        log_mel = log_mel[:, :fixed_length]\n",
        "    lo, hi = log_mel.min(), log_mel.max()\n",
        "    if hi - lo > 1e-6:\n",
        "        log_mel = (log_mel - lo) / (hi - lo)\n",
        "    return log_mel.astype(np.float32)\n",
        "\n",
        "# ── Metadata ──\n",
        "def load_metadata(root):\n",
        "    return pd.read_csv(os.path.join(root, 'metadata', 'UrbanSound8K.csv'))\n",
        "\n",
        "def audio_path(root, fold, fname):\n",
        "    return os.path.join(root, 'audio', f'fold{fold}', fname)\n",
        "\n",
        "def get_fold_splits(meta):\n",
        "    for fold in sorted(meta['fold'].unique()):\n",
        "        yield fold, meta[meta['fold'] != fold].copy(), meta[meta['fold'] == fold].copy()\n",
        "\n",
        "print('Core utilities loaded.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Cell 6: Dataset + Models ─────────────────────────────────────\n",
        "\n",
        "class MelDataset(Dataset):\n",
        "    def __init__(self, df, root, augment=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.root = root\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        y = load_audio(audio_path(self.root, row['fold'], row['slice_file_name']))\n",
        "        if self.augment:\n",
        "            shift = int(np.random.uniform(-0.1, 0.1) * len(y))\n",
        "            y = np.roll(y, shift)\n",
        "            y += np.random.normal(0, 0.005, y.shape).astype(y.dtype)\n",
        "        mel = torch.from_numpy(extract_mel(y)).unsqueeze(0)\n",
        "        return mel, torch.tensor(int(row['classID']), dtype=torch.long)\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, pool=True):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2) if pool else nn.Identity()\n",
        "        )\n",
        "    def forward(self, x): return self.block(x)\n",
        "\n",
        "\n",
        "class UrbanCNN(nn.Module):\n",
        "    def __init__(self, n_classes=10, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            ConvBlock(1,   32),\n",
        "            ConvBlock(32,  64),\n",
        "            ConvBlock(64,  128),\n",
        "            ConvBlock(128, 256),\n",
        "        )\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256*8*8, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(512, n_classes)\n",
        "        )\n",
        "    def forward(self, x): return self.head(self.features(x))\n",
        "\n",
        "\n",
        "print('Dataset and model classes defined.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Cell 7: Config ───────────────────────────────────────────────\n",
        "# Adjust these based on your GPU\n",
        "# T4:   BATCH_SIZE=64,  NUM_WORKERS=2\n",
        "# V100: BATCH_SIZE=128, NUM_WORKERS=4\n",
        "# A100: BATCH_SIZE=256, NUM_WORKERS=4\n",
        "\n",
        "BATCH_SIZE  = 64     # ← change based on GPU above\n",
        "EPOCHS      = 60\n",
        "LR          = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "NUM_WORKERS = 2      # ← change based on GPU above\n",
        "\n",
        "PROGRESS_FILE = os.path.join(CHECKPOINT_DIR, 'progress.json')\n",
        "\n",
        "print(f'Batch size: {BATCH_SIZE}')\n",
        "print(f'Epochs: {EPOCHS}')\n",
        "print(f'Progress file: {PROGRESS_FILE}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Cell 8: Training helpers ─────────────────────────────────────\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def train_epoch(model, loader, opt, criterion, scaler=None):\n",
        "    model.train()\n",
        "    total_loss = correct = total = 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        opt.zero_grad()\n",
        "        if scaler:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                out = model(x); loss = criterion(out, y)\n",
        "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "        else:\n",
        "            out = model(x); loss = criterion(out, y)\n",
        "            loss.backward(); opt.step()\n",
        "        total_loss += loss.item() * len(y)\n",
        "        correct += (out.argmax(1) == y).sum().item()\n",
        "        total += len(y)\n",
        "    return total_loss / total, correct / total\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_model(model, loader):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "    for x, y in loader:\n",
        "        preds.extend(model(x.to(DEVICE)).argmax(1).cpu().tolist())\n",
        "        labels.extend(y.tolist())\n",
        "    return np.array(labels), np.array(preds)\n",
        "\n",
        "def load_progress():\n",
        "    if os.path.exists(PROGRESS_FILE):\n",
        "        with open(PROGRESS_FILE) as f: return json.load(f)\n",
        "    return {'completed_folds': [], 'fold_results': []}\n",
        "\n",
        "def save_progress(prog):\n",
        "    with open(PROGRESS_FILE, 'w') as f: json.dump(prog, f, indent=2)\n",
        "\n",
        "print('Training helpers defined.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Cell 9: SVM Baseline ─────────────────────────────────────────\n",
        "# Run this once — takes ~15-30 min on Colab CPU\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "SVM_RESULTS_FILE = os.path.join(RESULTS_DIR, 'svm_results.json')\n",
        "\n",
        "if os.path.exists(SVM_RESULTS_FILE):\n",
        "    print('SVM results already exist. Loading from Drive...')\n",
        "    with open(SVM_RESULTS_FILE) as f:\n",
        "        svm_summary = json.load(f)\n",
        "    print(f\"SVM Mean Accuracy: {svm_summary['summary']['mean_accuracy']*100:.2f}%\")\n",
        "else:\n",
        "    meta = load_metadata(DATASET_ROOT)\n",
        "\n",
        "    # Pre-compute MFCC\n",
        "    mfcc_cache = os.path.join(CACHE_DIR, 'mfcc.npz')\n",
        "    if os.path.exists(mfcc_cache):\n",
        "        data = np.load(mfcc_cache)\n",
        "        X_all, y_all, folds_all = data['X'], data['y'], data['folds']\n",
        "        print('Loaded MFCC cache.')\n",
        "    else:\n",
        "        X_all, y_all, folds_all = [], [], []\n",
        "        for i, row in meta.iterrows():\n",
        "            path = audio_path(DATASET_ROOT, row['fold'], row['slice_file_name'])\n",
        "            audio = load_audio(path)\n",
        "            X_all.append(extract_mfcc(audio))\n",
        "            y_all.append(row['classID'])\n",
        "            folds_all.append(row['fold'])\n",
        "            if (i+1) % 1000 == 0: print(f'  MFCC {i+1}/{len(meta)}')\n",
        "        X_all = np.array(X_all, dtype=np.float32)\n",
        "        y_all = np.array(y_all, dtype=np.int64)\n",
        "        folds_all = np.array(folds_all)\n",
        "        np.savez(mfcc_cache, X=X_all, y=y_all, folds=folds_all)\n",
        "        print('MFCC cache saved.')\n",
        "\n",
        "    svm_fold_results = []\n",
        "    for fold, train_df, test_df in get_fold_splits(meta):\n",
        "        clf = Pipeline([('sc', StandardScaler()),\n",
        "                         ('svm', SVC(kernel='rbf', C=10, gamma='scale', cache_size=1000))])\n",
        "        tm = folds_all != fold\n",
        "        te = folds_all == fold\n",
        "        print(f'  SVM fold {fold}...')\n",
        "        clf.fit(X_all[tm], y_all[tm])\n",
        "        preds = clf.predict(X_all[te])\n",
        "        acc = accuracy_score(y_all[te], preds)\n",
        "        svm_fold_results.append({'fold': int(fold), 'accuracy': float(acc)})\n",
        "        print(f'  Fold {fold}: {acc*100:.2f}%')\n",
        "\n",
        "    accs = [r['accuracy'] for r in svm_fold_results]\n",
        "    svm_summary = {\n",
        "        'model': 'SVM+MFCC',\n",
        "        'summary': {'mean_accuracy': float(np.mean(accs)), 'std_accuracy': float(np.std(accs))},\n",
        "        'folds': svm_fold_results\n",
        "    }\n",
        "    with open(SVM_RESULTS_FILE, 'w') as f: json.dump(svm_summary, f, indent=2)\n",
        "    print(f\"\\nSVM Mean: {np.mean(accs)*100:.2f}% ± {np.std(accs)*100:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Cell 10: CNN Training (multi-session) ────────────────────────\n",
        "# Safe to re-run: skips completed folds automatically\n",
        "\n",
        "meta = load_metadata(DATASET_ROOT)\n",
        "prog = load_progress()\n",
        "completed = set(prog['completed_folds'])\n",
        "fold_results = prog['fold_results']\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler() if DEVICE.type == 'cuda' else None\n",
        "\n",
        "for test_fold, train_df, test_df in get_fold_splits(meta):\n",
        "    if test_fold in completed:\n",
        "        matching = [r for r in fold_results if r.get('fold') == test_fold]\n",
        "        if matching:\n",
        "            print(f'[SKIP] Fold {test_fold} — {matching[0][\"accuracy\"]*100:.2f}%')\n",
        "        continue\n",
        "\n",
        "    print(f'\\n── Fold {test_fold} ── {len(train_df)} train / {len(test_df)} test')\n",
        "\n",
        "    ckpt_best   = os.path.join(CHECKPOINT_DIR, f'fold{test_fold}_best.pt')\n",
        "    ckpt_resume = os.path.join(CHECKPOINT_DIR, f'fold{test_fold}_resume.pt')\n",
        "\n",
        "    train_ds = MelDataset(train_df, DATASET_ROOT, augment=True)\n",
        "    test_ds  = MelDataset(test_df,  DATASET_ROOT, augment=False)\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                               num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
        "                               num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "    model = UrbanCNN().to(DEVICE)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    start_epoch = 1\n",
        "    best_acc = 0.0\n",
        "\n",
        "    if os.path.exists(ckpt_resume):\n",
        "        state = torch.load(ckpt_resume, map_location=DEVICE)\n",
        "        model.load_state_dict(state['model'])\n",
        "        opt.load_state_dict(state['optimizer'])\n",
        "        sched.load_state_dict(state['scheduler'])\n",
        "        start_epoch = state['epoch'] + 1\n",
        "        best_acc = state['best_acc']\n",
        "        print(f'Resumed from epoch {start_epoch}, best_acc={best_acc*100:.2f}%')\n",
        "\n",
        "    for epoch in range(start_epoch, EPOCHS + 1):\n",
        "        loss, train_acc = train_epoch(model, train_loader, opt, crit, scaler)\n",
        "        sched.step()\n",
        "\n",
        "        if epoch % 5 == 0 or epoch == EPOCHS:\n",
        "            # Save resume state to Drive\n",
        "            torch.save({'epoch': epoch, 'model': model.state_dict(),\n",
        "                         'optimizer': opt.state_dict(), 'scheduler': sched.state_dict(),\n",
        "                         'best_acc': best_acc}, ckpt_resume)\n",
        "\n",
        "            labels, preds = eval_model(model, test_loader)\n",
        "            val_acc = (labels == preds).mean()\n",
        "            print(f'  E{epoch:02d}/{EPOCHS}  loss={loss:.4f}  '\n",
        "                  f'train={train_acc*100:.1f}%  val={val_acc*100:.1f}%')\n",
        "\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save(model.state_dict(), ckpt_best)\n",
        "\n",
        "    # Final eval\n",
        "    model.load_state_dict(torch.load(ckpt_best, map_location=DEVICE))\n",
        "    labels, preds = eval_model(model, test_loader)\n",
        "    acc = float((labels == preds).mean())\n",
        "\n",
        "    fold_results.append({'fold': int(test_fold), 'accuracy': acc})\n",
        "    completed.add(test_fold)\n",
        "    prog['completed_folds'] = list(completed)\n",
        "    prog['fold_results'] = fold_results\n",
        "    save_progress(prog)\n",
        "\n",
        "    if os.path.exists(ckpt_resume): os.remove(ckpt_resume)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(f'  Fold {test_fold} DONE — {acc*100:.2f}%')\n",
        "\n",
        "print('\\n── All folds complete ──')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Cell 11: Final summary & comparison ─────────────────────────\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# CNN results\n",
        "prog = load_progress()\n",
        "cnn_accs = [r['accuracy'] for r in prog['fold_results']]\n",
        "print('CNN Results:')\n",
        "for r in sorted(prog['fold_results'], key=lambda x: x['fold']):\n",
        "    print(f'  Fold {r[\"fold\"]:2d}: {r[\"accuracy\"]*100:.2f}%')\n",
        "print(f'  Mean: {np.mean(cnn_accs)*100:.2f}% ± {np.std(cnn_accs)*100:.2f}%')\n",
        "\n",
        "# SVM results\n",
        "if os.path.exists(SVM_RESULTS_FILE):\n",
        "    with open(SVM_RESULTS_FILE) as f: svm = json.load(f)\n",
        "    svm_accs = [r['accuracy'] for r in svm['folds']]\n",
        "    print(f\"\\nSVM Baseline: {np.mean(svm_accs)*100:.2f}% ± {np.std(svm_accs)*100:.2f}%\")\n",
        "\n",
        "# Save CNN results\n",
        "cnn_summary = {\n",
        "    'model': 'UrbanCNN',\n",
        "    'summary': {'mean_accuracy': float(np.mean(cnn_accs)), 'std_accuracy': float(np.std(cnn_accs))},\n",
        "    'folds': prog['fold_results']\n",
        "}\n",
        "with open(os.path.join(RESULTS_DIR, 'cnn_results.json'), 'w') as f:\n",
        "    json.dump(cnn_summary, f, indent=2)\n",
        "print('\\nResults saved to Drive.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Cell 12: Confusion matrix (run after all folds complete) ─────\n",
        "# Re-runs inference on fold 10 for confusion matrix visualization\n",
        "# You can pick any fold, or aggregate all\n",
        "\n",
        "meta = load_metadata(DATASET_ROOT)\n",
        "all_labels, all_preds = [], []\n",
        "\n",
        "for test_fold, train_df, test_df in get_fold_splits(meta):\n",
        "    ckpt = os.path.join(CHECKPOINT_DIR, f'fold{test_fold}_best.pt')\n",
        "    if not os.path.exists(ckpt):\n",
        "        print(f'Missing checkpoint for fold {test_fold}')\n",
        "        continue\n",
        "\n",
        "    test_ds = MelDataset(test_df, DATASET_ROOT, augment=False)\n",
        "    test_loader = DataLoader(test_ds, batch_size=64, shuffle=False,\n",
        "                              num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = UrbanCNN().to(DEVICE)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=DEVICE))\n",
        "\n",
        "    labels, preds = eval_model(model, test_loader)\n",
        "    all_labels.extend(labels.tolist())\n",
        "    all_preds.extend(preds.tolist())\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Overall accuracy: {accuracy_score(all_labels, all_preds)*100:.2f}%')\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=CLASSES, yticklabels=CLASSES, ax=ax)\n",
        "ax.set_xlabel('Predicted'); ax.set_ylabel('True')\n",
        "ax.set_title('Confusion Matrix — UrbanCNN (all folds)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, 'confusion_matrix.png'), dpi=150)\n",
        "plt.show()\n",
        "print('Saved to Drive.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
