{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtJ1j0HXsySy"
      },
      "source": [
        "# UrbanSound8K Classification — Colab Pro\n",
        "\n",
        "**Hardware options (Runtime → Change runtime type):**\n",
        "- `T4 GPU` — Free / Pro: baseline option, ~16 GB VRAM\n",
        "- `A100 GPU` — Pro+: fastest, use if available\n",
        "- `V100 GPU` — Pro: good middle ground\n",
        "- `TPU v2-8` — Experimental only; PyTorch on TPU requires extra setup, **use GPU instead**\n",
        "\n",
        "**Recommended for this project: T4 or A100 GPU**\n",
        "\n",
        "This notebook persists all checkpoints to Google Drive.\n",
        "Run it across multiple sessions — completed folds are skipped automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21RSWWyWsySz",
        "outputId": "d3a48e6c-00aa-4f79-9aa1-6ac6bfd1847c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/urbansound'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 18 (delta 3), reused 18 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (18/18), 24.88 KiB | 4.15 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "/content/urbansound\n",
            "Repo ready.\n"
          ]
        }
      ],
      "source": [
        "# ── Cell 0: Clone repo from GitHub ──────────────────────────────\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Pull token from Colab Secrets (never hardcode it)\n",
        "token = userdata.get('GITHUB_TOKEN')\n",
        "!git config --global user.email \"dun011@ucsd.edu\"\n",
        "!git config --global user.name \"DanielNg520\n",
        "\n",
        "REPO = 'DanielNg520/Urbansound8k-spectrogram-CNN'  # ← edit this\n",
        "\n",
        "# Clone or pull latest\n",
        "if os.path.exists('/content/urbansound'):\n",
        "    # Already cloned — just pull latest changes\n",
        "    %cd /content/urbansound\n",
        "    !git pull https://{token}@github.com/{REPO}.git main\n",
        "else:\n",
        "    !git clone https://{token}@github.com/{REPO}.git /content/urbansound\n",
        "    %cd /content/urbansound\n",
        "\n",
        "# Add to Python path so core/ imports work\n",
        "import sys\n",
        "sys.path.insert(0, '/content/urbansound')\n",
        "\n",
        "print('Repo ready.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlXwtIY4syS0",
        "outputId": "bfd80ffe-1cc9-42f9-e937-3e9a78834c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n",
            "VRAM: 15.6 GB\n",
            "Device: cuda\n",
            "PyTorch: 2.9.0+cu128\n"
          ]
        }
      ],
      "source": [
        "# ── Cell 1: Check hardware ──────────────────────────────────────\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_mem  = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f'GPU: {gpu_name}')\n",
        "    print(f'VRAM: {gpu_mem:.1f} GB')\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    print('No GPU! Go to Runtime → Change runtime type → GPU')\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "print(f'Device: {DEVICE}')\n",
        "print(f'PyTorch: {torch.__version__}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZKzODeHsyS0",
        "outputId": "a71cca91-887d-4576-b9b2-fd35938ce198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive mounted.\n",
            "Dataset: /content/drive/MyDrive/ECE176_project/UrbanSound8K\n",
            "Dataset exists: True\n",
            "CSV exists: True\n"
          ]
        }
      ],
      "source": [
        "# ── Cell 2: Mount Drive & set paths ────────────────────────────\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "DRIVE_ROOT     = '/content/drive/MyDrive/ECE176_project'\n",
        "DATASET_ROOT   = os.path.join(DRIVE_ROOT, 'UrbanSound8K')   # ← this is the fix\n",
        "CHECKPOINT_DIR = os.path.join(DRIVE_ROOT, 'checkpoints')\n",
        "RESULTS_DIR    = os.path.join(DRIVE_ROOT, 'results')\n",
        "CACHE_DIR      = os.path.join(DRIVE_ROOT, 'cache')\n",
        "\n",
        "for d in [CHECKPOINT_DIR, RESULTS_DIR, CACHE_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "print('Drive mounted.')\n",
        "print(f'Dataset: {DATASET_ROOT}')\n",
        "print(f'Dataset exists: {os.path.exists(DATASET_ROOT)}')\n",
        "print(f'CSV exists: {os.path.exists(os.path.join(DATASET_ROOT, \"metadata\", \"UrbanSound8K.csv\"))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi-M_jk-syS0",
        "outputId": "6c1c0f1f-eaa6-4ba9-adbe-c2d3fdd27afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading UrbanSound8K...\n",
            "Using Colab cache for faster access to the 'urbansound8k' dataset.\n",
            "Downloaded to: /kaggle/input/urbansound8k\n",
            "Removing previous copy...\n",
            "  Copying fold7...\n",
            "  Copying fold1...\n",
            "  Copying fold3...\n",
            "  Copying fold5...\n",
            "  Copying fold10...\n",
            "  Copying UrbanSound8K.csv...\n",
            "  Copying fold9...\n",
            "  Copying fold8...\n",
            "  Copying fold4...\n",
            "  Copying fold2...\n",
            "  Copying fold6...\n",
            "\n",
            "metadata/UrbanSound8K.csv: True\n",
            "audio/ folders: ['fold1', 'fold10', 'fold2', 'fold3', 'fold4', 'fold5', 'fold6', 'fold7', 'fold8', 'fold9']\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# ── Cell 3: Dataset setup ────────────────────────────────────────\n",
        "import os\n",
        "import shutil\n",
        "import kagglehub\n",
        "from google.colab import userdata\n",
        "import json\n",
        "\n",
        "dst = '/content/drive/MyDrive/ECE176_project/UrbanSound8K'\n",
        "csv_path = os.path.join(dst, 'metadata', 'UrbanSound8K.csv')\n",
        "\n",
        "if os.path.exists(csv_path):\n",
        "    print('Dataset already in Drive with correct structure. Skipping.')\n",
        "else:\n",
        "    # Set Kaggle credentials\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "    with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
        "        json.dump({\n",
        "            \"username\": userdata.get('KAGGLE_USERNAME'),\n",
        "            \"key\":      userdata.get('KAGGLE_KEY')\n",
        "        }, f)\n",
        "    os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
        "\n",
        "    # Download\n",
        "    print('Downloading UrbanSound8K...')\n",
        "    src = kagglehub.dataset_download('chrisfilo/urbansound8k')\n",
        "    print(f'Downloaded to: {src}')\n",
        "\n",
        "    # Delete any previous bad copy\n",
        "    if os.path.exists(dst):\n",
        "        print('Removing previous copy...')\n",
        "        shutil.rmtree(dst)\n",
        "\n",
        "    # Rebuild correct structure\n",
        "    os.makedirs(os.path.join(dst, 'audio'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(dst, 'metadata'), exist_ok=True)\n",
        "\n",
        "    for item in os.listdir(src):\n",
        "        full = os.path.join(src, item)\n",
        "        if item.startswith('fold'):\n",
        "            print(f'  Copying {item}...')\n",
        "            shutil.copytree(full, os.path.join(dst, 'audio', item))\n",
        "        elif item.endswith('.csv'):\n",
        "            print(f'  Copying {item}...')\n",
        "            shutil.copy2(full, os.path.join(dst, 'metadata', 'UrbanSound8K.csv'))\n",
        "\n",
        "    # Verify\n",
        "    print(f'\\nmetadata/UrbanSound8K.csv: {os.path.exists(csv_path)}')\n",
        "    print(f'audio/ folders: {sorted(os.listdir(os.path.join(dst, \"audio\")))}')\n",
        "    print('Done.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yehhaYAgsyS1"
      },
      "outputs": [],
      "source": [
        "# ── Cell 4: Install dependencies ────────────────────────────────\n",
        "!pip install -q librosa scikit-learn tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6ecSDc1syS1",
        "outputId": "36e28b09-c535-41f4-aa70-8be37e7a61c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Core utilities loaded.\n"
          ]
        }
      ],
      "source": [
        "# ── Cell 5: Core utilities (inline — no local files needed) ─────\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import json\n",
        "\n",
        "# ── Constants ──\n",
        "CLASSES = ['air_conditioner','car_horn','children_playing','dog_bark',\n",
        "           'drilling','engine_idling','gun_shot','jackhammer','siren','street_music']\n",
        "SAMPLE_RATE = 22050\n",
        "CLIP_DURATION = 4.0\n",
        "N_MFCC = 40\n",
        "N_MELS = 128\n",
        "HOP_LENGTH = 512\n",
        "N_FFT = 2048\n",
        "MEL_LENGTH = 128\n",
        "\n",
        "# ── Audio loading ──\n",
        "def load_audio(path, sr=SAMPLE_RATE, duration=CLIP_DURATION):\n",
        "    try:\n",
        "        y, _ = librosa.load(path, sr=sr, duration=duration, mono=True)\n",
        "    except:\n",
        "        return np.zeros(int(sr * duration), dtype=np.float32)\n",
        "    target_len = int(sr * duration)\n",
        "    if len(y) < target_len:\n",
        "        y = np.pad(y, (0, target_len - len(y)))\n",
        "    return y[:target_len].astype(np.float32)\n",
        "\n",
        "# ── Feature extraction ──\n",
        "def extract_mfcc(y, sr=SAMPLE_RATE):\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
        "    return np.concatenate([mfcc.mean(axis=1), mfcc.std(axis=1)])\n",
        "\n",
        "def extract_mel(y, sr=SAMPLE_RATE, fixed_length=MEL_LENGTH):\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS,\n",
        "                                          n_fft=N_FFT, hop_length=HOP_LENGTH, fmax=8000)\n",
        "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
        "    if log_mel.shape[1] < fixed_length:\n",
        "        log_mel = np.pad(log_mel, ((0,0),(0, fixed_length - log_mel.shape[1])),\n",
        "                         constant_values=log_mel.min())\n",
        "    else:\n",
        "        log_mel = log_mel[:, :fixed_length]\n",
        "    lo, hi = log_mel.min(), log_mel.max()\n",
        "    if hi - lo > 1e-6:\n",
        "        log_mel = (log_mel - lo) / (hi - lo)\n",
        "    return log_mel.astype(np.float32)\n",
        "\n",
        "# ── Metadata ──\n",
        "def load_metadata(root):\n",
        "    return pd.read_csv(os.path.join(root, 'metadata', 'UrbanSound8K.csv'))\n",
        "\n",
        "def audio_path(root, fold, fname):\n",
        "    return os.path.join(root, 'audio', f'fold{fold}', fname)\n",
        "\n",
        "def get_fold_splits(meta):\n",
        "    for fold in sorted(meta['fold'].unique()):\n",
        "        yield fold, meta[meta['fold'] != fold].copy(), meta[meta['fold'] == fold].copy()\n",
        "\n",
        "print('Core utilities loaded.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-4w6FDksyS1",
        "outputId": "24b1a060-ead3-40ca-f6df-5717231dc00a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset and model classes defined.\n"
          ]
        }
      ],
      "source": [
        "# ── Cell 6: Dataset + Models ─────────────────────────────────────\n",
        "\n",
        "class MelDataset(Dataset):\n",
        "    def __init__(self, df, root, augment=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.root = root\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        y = load_audio(audio_path(self.root, row['fold'], row['slice_file_name']))\n",
        "        if self.augment:\n",
        "            shift = int(np.random.uniform(-0.1, 0.1) * len(y))\n",
        "            y = np.roll(y, shift)\n",
        "            y += np.random.normal(0, 0.005, y.shape).astype(y.dtype)\n",
        "        mel = torch.from_numpy(extract_mel(y)).unsqueeze(0)\n",
        "        return mel, torch.tensor(int(row['classID']), dtype=torch.long)\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, pool=True):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2) if pool else nn.Identity()\n",
        "        )\n",
        "    def forward(self, x): return self.block(x)\n",
        "\n",
        "\n",
        "class UrbanCNN(nn.Module):\n",
        "    def __init__(self, n_classes=10, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            ConvBlock(1,   32),\n",
        "            ConvBlock(32,  64),\n",
        "            ConvBlock(64,  128),\n",
        "            ConvBlock(128, 256),\n",
        "        )\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256*8*8, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(512, n_classes)\n",
        "        )\n",
        "    def forward(self, x): return self.head(self.features(x))\n",
        "\n",
        "\n",
        "print('Dataset and model classes defined.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu6K0Th9syS1",
        "outputId": "ef566a90-53ed-42af-cf17-597031f87be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: 64\n",
            "Epochs: 60\n",
            "Progress file: /content/drive/MyDrive/ECE176_project/checkpoints/progress.json\n"
          ]
        }
      ],
      "source": [
        "# ── Cell 7: Config ───────────────────────────────────────────────\n",
        "# Adjust these based on your GPU\n",
        "# T4:   BATCH_SIZE=64,  NUM_WORKERS=2\n",
        "# V100: BATCH_SIZE=128, NUM_WORKERS=4\n",
        "# A100: BATCH_SIZE=256, NUM_WORKERS=4\n",
        "\n",
        "BATCH_SIZE  = 64     # ← change based on GPU above\n",
        "EPOCHS      = 60\n",
        "LR          = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "NUM_WORKERS = 2      # ← change based on GPU above\n",
        "\n",
        "PROGRESS_FILE = os.path.join(CHECKPOINT_DIR, 'progress.json')\n",
        "\n",
        "print(f'Batch size: {BATCH_SIZE}')\n",
        "print(f'Epochs: {EPOCHS}')\n",
        "print(f'Progress file: {PROGRESS_FILE}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLCq3l6QsyS2",
        "outputId": "40d3dd7b-b548-408c-9cfb-b51b767e4e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training helpers defined.\n"
          ]
        }
      ],
      "source": [
        "# ── Cell 8: Training helpers ─────────────────────────────────────\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def train_epoch(model, loader, opt, criterion, scaler=None):\n",
        "    model.train()\n",
        "    total_loss = correct = total = 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        opt.zero_grad()\n",
        "        if scaler:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                out = model(x); loss = criterion(out, y)\n",
        "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "        else:\n",
        "            out = model(x); loss = criterion(out, y)\n",
        "            loss.backward(); opt.step()\n",
        "        total_loss += loss.item() * len(y)\n",
        "        correct += (out.argmax(1) == y).sum().item()\n",
        "        total += len(y)\n",
        "    return total_loss / total, correct / total\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_model(model, loader):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "    for x, y in loader:\n",
        "        preds.extend(model(x.to(DEVICE)).argmax(1).cpu().tolist())\n",
        "        labels.extend(y.tolist())\n",
        "    return np.array(labels), np.array(preds)\n",
        "\n",
        "def load_progress():\n",
        "    if os.path.exists(PROGRESS_FILE):\n",
        "        with open(PROGRESS_FILE) as f: return json.load(f)\n",
        "    return {'completed_folds': [], 'fold_results': []}\n",
        "\n",
        "def save_progress(prog):\n",
        "    with open(PROGRESS_FILE, 'w') as f: json.dump(prog, f, indent=2)\n",
        "\n",
        "print('Training helpers defined.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T794WxeSsyS2",
        "outputId": "2541d32c-bfe1-4b53-8f5f-a66f3d4feeca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  MFCC 1000/8732\n",
            "  MFCC 2000/8732\n",
            "  MFCC 3000/8732\n",
            "  MFCC 4000/8732\n",
            "  MFCC 5000/8732\n",
            "  MFCC 6000/8732\n",
            "  MFCC 7000/8732\n",
            "  MFCC 8000/8732\n",
            "MFCC cache saved.\n",
            "  SVM fold 1...\n",
            "  Fold 1: 60.02%\n",
            "  SVM fold 2...\n",
            "  Fold 2: 65.77%\n",
            "  SVM fold 3...\n",
            "  Fold 3: 60.54%\n",
            "  SVM fold 4...\n",
            "  Fold 4: 65.45%\n",
            "  SVM fold 5...\n",
            "  Fold 5: 75.53%\n",
            "  SVM fold 6...\n",
            "  Fold 6: 59.90%\n",
            "  SVM fold 7...\n",
            "  Fold 7: 70.88%\n",
            "  SVM fold 8...\n",
            "  Fold 8: 63.40%\n",
            "  SVM fold 9...\n",
            "  Fold 9: 69.36%\n",
            "  SVM fold 10...\n",
            "  Fold 10: 70.13%\n",
            "\n",
            "SVM Mean: 66.10% ± 5.03%\n"
          ]
        }
      ],
      "source": [
        "# ── Cell 9: SVM Baseline ─────────────────────────────────────────\n",
        "# Run this once — takes ~15-30 min on Colab CPU\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "SVM_RESULTS_FILE = os.path.join(RESULTS_DIR, 'svm_results.json')\n",
        "\n",
        "if os.path.exists(SVM_RESULTS_FILE):\n",
        "    print('SVM results already exist. Loading from Drive...')\n",
        "    with open(SVM_RESULTS_FILE) as f:\n",
        "        svm_summary = json.load(f)\n",
        "    print(f\"SVM Mean Accuracy: {svm_summary['summary']['mean_accuracy']*100:.2f}%\")\n",
        "else:\n",
        "    meta = load_metadata(DATASET_ROOT)\n",
        "\n",
        "    # Pre-compute MFCC\n",
        "    mfcc_cache = os.path.join(CACHE_DIR, 'mfcc.npz')\n",
        "    if os.path.exists(mfcc_cache):\n",
        "        data = np.load(mfcc_cache)\n",
        "        X_all, y_all, folds_all = data['X'], data['y'], data['folds']\n",
        "        print('Loaded MFCC cache.')\n",
        "    else:\n",
        "        X_all, y_all, folds_all = [], [], []\n",
        "        for i, row in meta.iterrows():\n",
        "            path = audio_path(DATASET_ROOT, row['fold'], row['slice_file_name'])\n",
        "            audio = load_audio(path)\n",
        "            X_all.append(extract_mfcc(audio))\n",
        "            y_all.append(row['classID'])\n",
        "            folds_all.append(row['fold'])\n",
        "            if (i+1) % 1000 == 0: print(f'  MFCC {i+1}/{len(meta)}')\n",
        "        X_all = np.array(X_all, dtype=np.float32)\n",
        "        y_all = np.array(y_all, dtype=np.int64)\n",
        "        folds_all = np.array(folds_all)\n",
        "        np.savez(mfcc_cache, X=X_all, y=y_all, folds=folds_all)\n",
        "        print('MFCC cache saved.')\n",
        "\n",
        "    svm_fold_results = []\n",
        "    for fold, train_df, test_df in get_fold_splits(meta):\n",
        "        clf = Pipeline([('sc', StandardScaler()),\n",
        "                         ('svm', SVC(kernel='rbf', C=10, gamma='scale', cache_size=1000))])\n",
        "        tm = folds_all != fold\n",
        "        te = folds_all == fold\n",
        "        print(f'  SVM fold {fold}...')\n",
        "        clf.fit(X_all[tm], y_all[tm])\n",
        "        preds = clf.predict(X_all[te])\n",
        "        acc = accuracy_score(y_all[te], preds)\n",
        "        svm_fold_results.append({'fold': int(fold), 'accuracy': float(acc)})\n",
        "        print(f'  Fold {fold}: {acc*100:.2f}%')\n",
        "\n",
        "    accs = [r['accuracy'] for r in svm_fold_results]\n",
        "    svm_summary = {\n",
        "        'model': 'SVM+MFCC',\n",
        "        'summary': {'mean_accuracy': float(np.mean(accs)), 'std_accuracy': float(np.std(accs))},\n",
        "        'folds': svm_fold_results\n",
        "    }\n",
        "    with open(SVM_RESULTS_FILE, 'w') as f: json.dump(svm_summary, f, indent=2)\n",
        "    print(f\"\\nSVM Mean: {np.mean(accs)*100:.2f}% ± {np.std(accs)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTrBeS1OsyS2"
      },
      "outputs": [],
      "source": [
        "# ── Cell 10: CNN Training (multi-session) ────────────────────────\n",
        "# Safe to re-run: skips completed folds automatically\n",
        "\n",
        "meta = load_metadata(DATASET_ROOT)\n",
        "prog = load_progress()\n",
        "completed = set(prog['completed_folds'])\n",
        "fold_results = prog['fold_results']\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler() if DEVICE.type == 'cuda' else None\n",
        "\n",
        "for test_fold, train_df, test_df in get_fold_splits(meta):\n",
        "    if test_fold in completed:\n",
        "        matching = [r for r in fold_results if r.get('fold') == test_fold]\n",
        "        if matching:\n",
        "            print(f'[SKIP] Fold {test_fold} — {matching[0][\"accuracy\"]*100:.2f}%')\n",
        "        continue\n",
        "\n",
        "    print(f'\\n── Fold {test_fold} ── {len(train_df)} train / {len(test_df)} test')\n",
        "\n",
        "    ckpt_best   = os.path.join(CHECKPOINT_DIR, f'fold{test_fold}_best.pt')\n",
        "    ckpt_resume = os.path.join(CHECKPOINT_DIR, f'fold{test_fold}_resume.pt')\n",
        "\n",
        "    train_ds = MelDataset(train_df, DATASET_ROOT, augment=True)\n",
        "    test_ds  = MelDataset(test_df,  DATASET_ROOT, augment=False)\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                               num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
        "                               num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "    model = UrbanCNN().to(DEVICE)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    start_epoch = 1\n",
        "    best_acc = 0.0\n",
        "\n",
        "    if os.path.exists(ckpt_resume):\n",
        "        state = torch.load(ckpt_resume, map_location=DEVICE)\n",
        "        model.load_state_dict(state['model'])\n",
        "        opt.load_state_dict(state['optimizer'])\n",
        "        sched.load_state_dict(state['scheduler'])\n",
        "        start_epoch = state['epoch'] + 1\n",
        "        best_acc = state['best_acc']\n",
        "        print(f'Resumed from epoch {start_epoch}, best_acc={best_acc*100:.2f}%')\n",
        "\n",
        "    for epoch in range(start_epoch, EPOCHS + 1):\n",
        "        loss, train_acc = train_epoch(model, train_loader, opt, crit, scaler)\n",
        "        sched.step()\n",
        "\n",
        "        if epoch % 5 == 0 or epoch == EPOCHS:\n",
        "            # Save resume state to Drive\n",
        "            torch.save({'epoch': epoch, 'model': model.state_dict(),\n",
        "                         'optimizer': opt.state_dict(), 'scheduler': sched.state_dict(),\n",
        "                         'best_acc': best_acc}, ckpt_resume)\n",
        "\n",
        "            labels, preds = eval_model(model, test_loader)\n",
        "            val_acc = (labels == preds).mean()\n",
        "            print(f'  E{epoch:02d}/{EPOCHS}  loss={loss:.4f}  '\n",
        "                  f'train={train_acc*100:.1f}%  val={val_acc*100:.1f}%')\n",
        "\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save(model.state_dict(), ckpt_best)\n",
        "\n",
        "    # Final eval\n",
        "    model.load_state_dict(torch.load(ckpt_best, map_location=DEVICE))\n",
        "    labels, preds = eval_model(model, test_loader)\n",
        "    acc = float((labels == preds).mean())\n",
        "\n",
        "    fold_results.append({'fold': int(test_fold), 'accuracy': acc})\n",
        "    completed.add(test_fold)\n",
        "    prog['completed_folds'] = list(completed)\n",
        "    prog['fold_results'] = fold_results\n",
        "    save_progress(prog)\n",
        "\n",
        "    if os.path.exists(ckpt_resume): os.remove(ckpt_resume)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(f'  Fold {test_fold} DONE — {acc*100:.2f}%')\n",
        "\n",
        "print('\\n── All folds complete ──')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F08z0KIsyS2"
      },
      "outputs": [],
      "source": [
        "# ── Cell 11: Final summary & comparison ─────────────────────────\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# CNN results\n",
        "prog = load_progress()\n",
        "cnn_accs = [r['accuracy'] for r in prog['fold_results']]\n",
        "print('CNN Results:')\n",
        "for r in sorted(prog['fold_results'], key=lambda x: x['fold']):\n",
        "    print(f'  Fold {r[\"fold\"]:2d}: {r[\"accuracy\"]*100:.2f}%')\n",
        "print(f'  Mean: {np.mean(cnn_accs)*100:.2f}% ± {np.std(cnn_accs)*100:.2f}%')\n",
        "\n",
        "# SVM results\n",
        "if os.path.exists(SVM_RESULTS_FILE):\n",
        "    with open(SVM_RESULTS_FILE) as f: svm = json.load(f)\n",
        "    svm_accs = [r['accuracy'] for r in svm['folds']]\n",
        "    print(f\"\\nSVM Baseline: {np.mean(svm_accs)*100:.2f}% ± {np.std(svm_accs)*100:.2f}%\")\n",
        "\n",
        "# Save CNN results\n",
        "cnn_summary = {\n",
        "    'model': 'UrbanCNN',\n",
        "    'summary': {'mean_accuracy': float(np.mean(cnn_accs)), 'std_accuracy': float(np.std(cnn_accs))},\n",
        "    'folds': prog['fold_results']\n",
        "}\n",
        "with open(os.path.join(RESULTS_DIR, 'cnn_results.json'), 'w') as f:\n",
        "    json.dump(cnn_summary, f, indent=2)\n",
        "print('\\nResults saved to Drive.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEcyiGIlsyS2"
      },
      "outputs": [],
      "source": [
        "# ── Cell 12: Confusion matrix (run after all folds complete) ─────\n",
        "# Re-runs inference on fold 10 for confusion matrix visualization\n",
        "# You can pick any fold, or aggregate all\n",
        "\n",
        "meta = load_metadata(DATASET_ROOT)\n",
        "all_labels, all_preds = [], []\n",
        "\n",
        "for test_fold, train_df, test_df in get_fold_splits(meta):\n",
        "    ckpt = os.path.join(CHECKPOINT_DIR, f'fold{test_fold}_best.pt')\n",
        "    if not os.path.exists(ckpt):\n",
        "        print(f'Missing checkpoint for fold {test_fold}')\n",
        "        continue\n",
        "\n",
        "    test_ds = MelDataset(test_df, DATASET_ROOT, augment=False)\n",
        "    test_loader = DataLoader(test_ds, batch_size=64, shuffle=False,\n",
        "                              num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = UrbanCNN().to(DEVICE)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=DEVICE))\n",
        "\n",
        "    labels, preds = eval_model(model, test_loader)\n",
        "    all_labels.extend(labels.tolist())\n",
        "    all_preds.extend(preds.tolist())\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Overall accuracy: {accuracy_score(all_labels, all_preds)*100:.2f}%')\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=CLASSES, yticklabels=CLASSES, ax=ax)\n",
        "ax.set_xlabel('Predicted'); ax.set_ylabel('True')\n",
        "ax.set_title('Confusion Matrix — UrbanCNN (all folds)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, 'confusion_matrix.png'), dpi=150)\n",
        "plt.show()\n",
        "print('Saved to Drive.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extra Git Push\n",
        "!git config --global user.email \"dun011@ucsd.edu\"\n",
        "!git config --global user.name \"DanielNg520\"\n",
        "\n",
        "!git add v3_colab_pro.ipynb\n",
        "!git commit -m \"fix DATASET_ROOT path\"\n",
        "!git push"
      ],
      "metadata": {
        "id": "o2xzuB_q3Aw5",
        "outputId": "91595eb0-b8ab-4db4-aeb0-8d5f2f704a1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}